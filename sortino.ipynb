{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5423df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*                      3%                       ]  2 of 74 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  74 of 74 completed\n",
      "/tmp/ipykernel_17980/2612838569.py:27: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = data.pct_change().dropna()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m    100\u001b[39m weights = np.random.random(num_assets)\n\u001b[32m    101\u001b[39m weights /= np.sum(weights)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m returns_portfolio = np.dot(weights, \u001b[43mreturns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) * \u001b[32m252\u001b[39m\n\u001b[32m    103\u001b[39m volatility = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * \u001b[32m252\u001b[39m, weights)))\n\u001b[32m    104\u001b[39m sr = returns_portfolio / volatility\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:11693\u001b[39m, in \u001b[36mDataFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  11685\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n\u001b[32m  11686\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  11687\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11691\u001b[39m     **kwargs,\n\u001b[32m  11692\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m11693\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11694\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[32m  11695\u001b[39m         result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:12420\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12414\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12415\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12418\u001b[39m     **kwargs,\n\u001b[32m  12419\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12421\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:12377\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12373\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12375\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12379\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:11562\u001b[39m, in \u001b[36mDataFrame._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m  11558\u001b[39m     df = df.T\n\u001b[32m  11560\u001b[39m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[32m  11561\u001b[39m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11562\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11563\u001b[39m out = df._constructor_from_mgr(res, axes=res.axes).iloc[\u001b[32m0\u001b[39m]\n\u001b[32m  11564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out.dtype != \u001b[33m\"\u001b[39m\u001b[33mboolean\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:1500\u001b[39m, in \u001b[36mBlockManager.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1498\u001b[39m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m     nbs = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1501\u001b[39m     res_blocks.extend(nbs)\n\u001b[32m   1503\u001b[39m index = Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/blocks.py:404\u001b[39m, in \u001b[36mBlock.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    400\u001b[39m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[32m    401\u001b[39m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    407\u001b[39m         res_values = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:11481\u001b[39m, in \u001b[36mDataFrame._reduce.<locals>.blk_func\u001b[39m\u001b[34m(values, axis)\u001b[39m\n\u001b[32m  11479\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.array([result])\n\u001b[32m  11480\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m11481\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:705\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    681\u001b[39m \u001b[33;03mCompute the mean of the element along an axis ignoring NaNs\u001b[39;00m\n\u001b[32m    682\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    702\u001b[39m \u001b[33;03m1.5\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    704\u001b[39m dtype = values.dtype\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m values, mask = \u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m dtype_sum = _get_dtype_max(dtype)\n\u001b[32m    707\u001b[39m dtype_count = np.dtype(np.float64)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:313\u001b[39m, in \u001b[36m_get_values\u001b[39m\u001b[34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[39m\n\u001b[32m    308\u001b[39m fill_value = _get_fill_value(\n\u001b[32m    309\u001b[39m     dtype, fill_value=fill_value, fill_value_typ=fill_value_typ\n\u001b[32m    310\u001b[39m )\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    314\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mor\u001b[39;00m _na_ok_dtype(dtype):\n\u001b[32m    315\u001b[39m             values = values.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/numpy/_core/_methods.py:64\u001b[39m, in \u001b[36m_any\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_any\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where=where)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats.mstats import gmean\n",
    "import shelve\n",
    "\n",
    "# Seleccionar Criterio de Optimización\n",
    "optimization_criterion = 'sortino'  # Cambia a 'sharpe', 'cvar', 'sortino' o 'variance' para optimizar esos criterios\n",
    "\n",
    "# Elegir Acciones por agregar al Protafolio y Seleccionar periodo de muestra\n",
    "# symbols = ['379800.KS', '379810.KS', 'BTC-KRW', '047810.KS', '012450.KS', 'AAPL', 'MSFT', 'NVDA', 'GOOG', 'AMZN', 'META', 'BRK-B', 'AVGO', 'TSM', 'WMT', 'LLY', 'JPM']\n",
    "symbols = []\n",
    "\n",
    "with shelve.open(\"ticker_cache\") as cache:\n",
    "    for ticker, name in cache.items():\n",
    "        symbols.append(ticker)\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2025-05-09'\n",
    "\n",
    "data = yf.download(symbols, start=start_date, end=end_date)['Close']\n",
    "\n",
    "# Calcular los retornos\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Definir la función objetivo para la optimización de la relación de Sharpe\n",
    "def objective_sharpe(weights): \n",
    "    return -np.dot(weights, returns.mean()) / np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))\n",
    "\n",
    "# Definir la función objetivo para la optimización del CVaR\n",
    "def objective_cvar(weights):\n",
    "    portfolio_returns = np.dot(returns, weights)\n",
    "    portfolio_mean = portfolio_returns.mean()\n",
    "    portfolio_std = portfolio_returns.std()\n",
    "    conf_level = 0.05  # Nivel de confianza para el CVaR\n",
    "    cvar = portfolio_mean - portfolio_std * norm.ppf(conf_level)\n",
    "    return cvar\n",
    "\n",
    "# Definir la función objetivo para la optimización de la relación de Sortino\n",
    "def objective_sortino(weights):\n",
    "    portfolio_returns = np.dot(returns, weights)\n",
    "    downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "    downside_std = downside_returns.std()\n",
    "    sortino_ratio = portfolio_returns.mean() / downside_std\n",
    "    return -sortino_ratio  # Maximizar la relación de Sortino\n",
    "\n",
    "# Definir la función objetivo para la minimización de la varianza\n",
    "def objective_variance(weights):\n",
    "    return np.dot(weights.T, np.dot(returns.cov() * 252, weights))\n",
    "\n",
    "# Las restricciones\n",
    "cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "\n",
    "# Los límites para los pesos\n",
    "bounds = tuple((0, 1) for x in range(len(symbols)))\n",
    "\n",
    "\n",
    "# Optimización\n",
    "init_guess = np.array(len(symbols) * [1. / len(symbols),])\n",
    "if optimization_criterion == 'sharpe':\n",
    "    opt_results = minimize(objective_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "elif optimization_criterion == 'cvar':\n",
    "    opt_results = minimize(objective_cvar, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "elif optimization_criterion == 'sortino':\n",
    "    opt_results = minimize(objective_sortino, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "elif optimization_criterion == 'variance':\n",
    "    opt_results = minimize(objective_variance, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "# Los pesos óptimos\n",
    "optimal_weights = opt_results.x\n",
    "\n",
    "\n",
    "# Optimizar todos los criterios\n",
    "opt_results_cvar = minimize(objective_cvar, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "opt_results_sortino = minimize(objective_sortino, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "opt_results_variance = minimize(objective_variance, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "opt_results_sharpe = minimize(objective_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "# Pesos óptimos para cada criterio\n",
    "optimal_weights_cvar = opt_results_cvar.x\n",
    "optimal_weights_sortino = opt_results_sortino.x\n",
    "optimal_weights_variance = opt_results_variance.x\n",
    "optimal_weights_sharpe = opt_results_sharpe.x\n",
    "\n",
    "# Graficar la frontera eficiente\n",
    "port_returns = []\n",
    "port_volatility = []\n",
    "sharpe_ratio = []\n",
    "all_weights = []  # almacena los pesos de todas las carteras simuladas\n",
    "\n",
    "num_assets = len(symbols)\n",
    "num_portfolios = 50000\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "for single_portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    returns_portfolio = np.dot(weights, returns.mean()) * 252\n",
    "    volatility = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))\n",
    "    sr = returns_portfolio / volatility\n",
    "    sharpe_ratio.append(sr)\n",
    "    port_returns.append(returns_portfolio)\n",
    "    port_volatility.append(volatility)\n",
    "    all_weights.append(weights)  # registra los pesos para esta cartera\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(port_volatility, port_returns, c=sharpe_ratio, cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Return')\n",
    "\n",
    "# Calcular y graficar los retornos y la volatilidad del portafolio óptimo para cada criterio\n",
    "opt_returns_cvar = np.dot(optimal_weights_cvar, returns.mean()) * 252\n",
    "opt_volatility_cvar = np.sqrt(np.dot(optimal_weights_cvar.T, np.dot(returns.cov() * 252, optimal_weights_cvar)))\n",
    "opt_portfolio_cvar = plt.scatter(opt_volatility_cvar, opt_returns_cvar, color='hotpink', s=50, label='CVaR')\n",
    "\n",
    "opt_returns_sortino = np.dot(optimal_weights_sortino, returns.mean()) * 252\n",
    "opt_volatility_sortino = np.sqrt(np.dot(optimal_weights_sortino.T, np.dot(returns.cov() * 252, optimal_weights_sortino)))\n",
    "opt_portfolio_sortino = plt.scatter(opt_volatility_sortino, opt_returns_sortino, color='g', s=50, label='Sortino')\n",
    "\n",
    "opt_returns_variance = np.dot(optimal_weights_variance, returns.mean()) * 252\n",
    "opt_volatility_variance = np.sqrt(np.dot(optimal_weights_variance.T, np.dot(returns.cov() * 252, optimal_weights_variance)))\n",
    "opt_portfolio_variance = plt.scatter(opt_volatility_variance, opt_returns_variance, color='b', s=50, label='Variance')\n",
    "\n",
    "opt_returns_sharpe = np.dot(optimal_weights_sharpe, returns.mean()) * 252\n",
    "opt_volatility_sharpe = np.sqrt(np.dot(optimal_weights_sharpe.T, np.dot(returns.cov() * 252, optimal_weights_sharpe)))\n",
    "opt_portfolio_sharpe = plt.scatter(opt_volatility_sharpe, opt_returns_sharpe, color='r', s=50, label='Sharpe')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Función para calcular el drawdown máximo\n",
    "def max_drawdown(return_series):\n",
    "    comp_ret = (1 + return_series).cumprod()\n",
    "    peak = comp_ret.expanding(min_periods=1).max()\n",
    "    dd = (comp_ret/peak) - 1\n",
    "    return dd.min()\n",
    "\n",
    "# Función para calcular estadísticas descriptivas más detalladas\n",
    "def detailed_portfolio_statistics(weights):\n",
    "    portfolio_returns = returns.dot(weights)\n",
    "    \n",
    "    # Estadísticas descriptivas generales\n",
    "    mean_return_annualized = gmean(portfolio_returns + 1)**252 - 1\n",
    "    std_dev_annualized = portfolio_returns.std() * np.sqrt(252)\n",
    "    skewness = skew(portfolio_returns)\n",
    "    kurt = kurtosis(portfolio_returns)\n",
    "    max_dd = max_drawdown(portfolio_returns)\n",
    "    count = len(portfolio_returns)\n",
    "    \n",
    "    # Métricas de optimización\n",
    "    risk_free_rate = 0.00\n",
    "    sharpe_ratio = (mean_return_annualized - risk_free_rate) / std_dev_annualized\n",
    "    conf_level = 0.05\n",
    "    cvar = mean_return_annualized - std_dev_annualized * norm.ppf(conf_level)\n",
    "    downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "    downside_std_dev = downside_returns.std() * np.sqrt(252)\n",
    "    sortino_ratio = mean_return_annualized / downside_std_dev\n",
    "    variance = std_dev_annualized ** 2 \n",
    "    \n",
    "    return mean_return_annualized, std_dev_annualized, skewness, kurt, max_dd, count, sharpe_ratio, cvar, sortino_ratio, variance\n",
    "\n",
    "# Calcular estadísticas para cada portafolio\n",
    "statistics_cvar = detailed_portfolio_statistics(optimal_weights_cvar)\n",
    "statistics_sortino = detailed_portfolio_statistics(optimal_weights_sortino)\n",
    "statistics_variance = detailed_portfolio_statistics(optimal_weights_variance)\n",
    "statistics_sharpe = detailed_portfolio_statistics(optimal_weights_sharpe)\n",
    "\n",
    "# Nombres de las estadísticas\n",
    "statistics_names = ['Retorno anualizado', 'Volatilidad anualizada', 'Skewness', 'Kurtosis', 'Max Drawdown', 'Conteo de datos', 'Sharpe Ratio', 'CVaR', 'Ratio Sortino', 'Varianza']\n",
    "\n",
    "# Diccionario que asocia los nombres de los métodos de optimización con los pesos óptimos y las estadísticas\n",
    "portfolio_data = {\n",
    "    'CVaR': {\n",
    "        'weights': optimal_weights_cvar,\n",
    "        'statistics': detailed_portfolio_statistics(optimal_weights_cvar)\n",
    "    },\n",
    "    'Sortino': {\n",
    "        'weights': optimal_weights_sortino,\n",
    "        'statistics': detailed_portfolio_statistics(optimal_weights_sortino)\n",
    "    },\n",
    "    'Variance': {\n",
    "        'weights': optimal_weights_variance,\n",
    "        'statistics': detailed_portfolio_statistics(optimal_weights_variance)\n",
    "    },\n",
    "    'Sharpe': {\n",
    "        'weights': optimal_weights_sharpe,\n",
    "        'statistics': detailed_portfolio_statistics(optimal_weights_sharpe)\n",
    "    },\n",
    "}\n",
    "\n",
    "# Imprimir los pesos y las estadísticas para cada método de optimización\n",
    "for method, data in portfolio_data.items():\n",
    "    print(\"\\n\")\n",
    "    print(\"========================================================================================================\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Pesos del portafolio óptimo para {method}:\")\n",
    "    print(\"\\n\")\n",
    "    for symbol, weight in zip(symbols, data['weights']):\n",
    "        if weight < 1e-4:  # considera cualquier peso menor que 0.01% como cero\n",
    "            print(f\"{symbol}: prácticamente 0%\")\n",
    "        else:\n",
    "            print(f\"{symbol}: {weight*100:.2f}%\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Estadísticas descriptivas del portafolio óptimo para {method}:\")\n",
    "    print(\"\\n\")\n",
    "    for name, stat in zip(statistics_names, data['statistics']):\n",
    "        print(f\"{name}: {stat*100 if name != 'Conteo de datos' else stat:.2f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"========================================================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
